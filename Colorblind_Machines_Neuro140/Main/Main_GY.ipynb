{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main_GY.ipynb","provenance":[{"file_id":"1jTmt_ugGx8CmuS-B4ZcDt1KUUC1QJvxF","timestamp":1617988216108}],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNRyfFHMVQyDhG6DFviviW0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0881cb5af516407686f5095fd5f3ef41":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1db1921b86f9416e84a2fbd81f2cd9b8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_44c8048dec0044d48f41f600bee5ab91","IPY_MODEL_4e3f12d708534e43b854dbaccad849d9"]}},"1db1921b86f9416e84a2fbd81f2cd9b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"44c8048dec0044d48f41f600bee5ab91":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_13a61e6f59234d46b1323ac6543e0f80","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"danger","max":4001,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84baaa2c82c54781a56f664bf44aa412"}},"4e3f12d708534e43b854dbaccad849d9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_30689d20f5f244f5a551cb877384d506","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/4001 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4ce65d6acc984aab91ff687bf96f1c48"}},"13a61e6f59234d46b1323ac6543e0f80":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"84baaa2c82c54781a56f664bf44aa412":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"30689d20f5f244f5a551cb877384d506":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4ce65d6acc984aab91ff687bf96f1c48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"8I65BronwUg2"},"source":["**Main Graycale Experiments**\n","Using the architecture provided in Assignment 2, I will run the my grayscale experiment. In this file, I will train a ResNet model on grayscaled CIFAR-10 images and then test the model on RGB images. I will then compare these findings to my control condition. "]},{"cell_type":"markdown","metadata":{"id":"sR20Ie3Vy_XL"},"source":["###The following code will be repeated for each experimental section to set up the workspace"]},{"cell_type":"code","metadata":{"id":"tx1UTR9nwO-O"},"source":["# The following code will be repeated for each experimental section>\n","### General libraries useful for python ###\n","\n","import os\n","import sys\n","from tqdm.notebook import tqdm\n","import json\n","import random\n","import pickle\n","import copy\n","from IPython.display import display\n","import ipywidgets as widgets"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cq1_8b-Axa-L","executionInfo":{"status":"ok","timestamp":1618108147862,"user_tz":240,"elapsed":1350,"user":{"displayName":"Abraham Dada","photoUrl":"","userId":"04289475073988443676"}},"outputId":"27a62f05-bdea-4232-933d-87a1b4e0b4c6"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBYo9vxspmkN","executionInfo":{"status":"ok","timestamp":1618108151008,"user_tz":240,"elapsed":410,"user":{"displayName":"Abraham Dada","photoUrl":"","userId":"04289475073988443676"}},"outputId":"8f0ee242-0168-483d-9abb-67e1c05be43b"},"source":["### Finding where you clone your repo, so that code upstream paths can be specified programmatically ####\n","git_dir = '/content/drive/MyDrive/Harvard_BAI'\n","print('Your github directory is :%s'%git_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Your github directory is :/content/drive/MyDrive/Harvard_BAI\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ciPtPbRNxvtR"},"source":["project_folder= \"%s/Colorblind_Machines_Neuro140\"%git_dir"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fVis-k3TyzuC"},"source":["# Change into project folder\n","os.chdir(project_folder)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rnod5WINy8Of"},"source":["### Libraries for visualizing our results and data ###\n","from PIL import Image\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3bx7u8CBzKKr"},"source":["### Import PyTorch and its components ###\n","import torch\n","import torchvision\n","from torchvision import transforms\n","import torch.nn as nn\n","import torch.optim as optim"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"502702xX0kuc"},"source":["#### Now we will load our code bases from assignment 2 "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tsZMfmnJ05jq","executionInfo":{"status":"ok","timestamp":1618108163393,"user_tz":240,"elapsed":495,"user":{"displayName":"Abraham Dada","photoUrl":"","userId":"04289475073988443676"}},"outputId":"34ac9b8b-6d8e-457a-b3f2-624e4d979bcc"},"source":["### Making helper code under the folder res available. This includes loaders, models, etc. ###\n","sys.path.append('%s/res/'%git_dir)\n","from models.models import get_model\n","from loader.loader import get_loader"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Models are being loaded from: /content/drive/MyDrive/Harvard_BAI/res/models\n","Loaders are being loaded from: /content/drive/MyDrive/Harvard_BAI/res/loader\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Uo4VWHas1O5-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618108184593,"user_tz":240,"elapsed":15898,"user":{"displayName":"Abraham Dada","photoUrl":"","userId":"04289475073988443676"}},"outputId":"494efecb-61a9-4745-a78b-835c3ae6e49f"},"source":["### Setting up Weights and Biases for tracking your experiments. ###\n","\n","## We have Weights and Biases (wandb.ai) integrated into the code for easy visualization of results and for tracking performance. \n","\n","%pip install --upgrade git+git://github.com/wandb/client.git@task/debug-init-wandb#egg=wandb\n","import wandb\n","wandb.login()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting wandb\n","  Cloning git://github.com/wandb/client.git (to revision task/debug-init-wandb) to /tmp/pip-install-va14q992/wandb\n","  Running command git clone -q git://github.com/wandb/client.git /tmp/pip-install-va14q992/wandb\n","  Running command git checkout -b task/debug-init-wandb --track origin/task/debug-init-wandb\n","  Switched to a new branch 'task/debug-init-wandb'\n","  Branch 'task/debug-init-wandb' set up to track remote branch 'task/debug-init-wandb' from 'origin'.\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied, skipping upgrade: sentry-sdk>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.0)\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied, skipping upgrade: subprocess32>=3.5.3 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.5.4)\n","Requirement already satisfied, skipping upgrade: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n","Requirement already satisfied, skipping upgrade: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied, skipping upgrade: Click>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied, skipping upgrade: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.14)\n","Requirement already satisfied, skipping upgrade: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.12.4)\n","Requirement already satisfied, skipping upgrade: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.1)\n","Requirement already satisfied, skipping upgrade: configparser>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.0.2)\n","Requirement already satisfied, skipping upgrade: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied, skipping upgrade: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied, skipping upgrade: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied, skipping upgrade: urllib3>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied, skipping upgrade: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.7)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.0->wandb) (54.2.0)\n","Requirement already satisfied, skipping upgrade: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (4.0.0)\n","Building wheels for collected packages: wandb\n","  Building wheel for wandb (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wandb: filename=wandb-0.10.18.dev1-cp37-none-any.whl size=2009263 sha256=e52d42ba3bf5d24d3f8051402f1bc169b46478bd3f767ba0ef5314c5ad2341eb\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-h_0ykesp/wheels/29/78/b2/765acd344a232f2054890239a1f4fa7910cd6c07dc337d004f\n","Successfully built wandb\n","Installing collected packages: wandb\n","  Found existing installation: wandb 0.10.18.dev1\n","    Uninstalling wandb-0.10.18.dev1:\n","      Successfully uninstalled wandb-0.10.18.dev1\n","Successfully installed wandb-0.10.18.dev1\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33madada21\u001b[0m (use `wandb login --relogin` to force relogin)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"daHfD-9b2JN4"},"source":["### Specifying settings/hyperparameters for the code below ###"]},{"cell_type":"code","metadata":{"id":"SHe1xKIQ2VGy"},"source":["wandb_config = {}\n","wandb_config['batch_size'] = 10\n","wandb_config['base_lr'] = 0.01\n","wandb_config['model_arch'] = 'ResNet18'\n","wandb_config['num_classes'] = 10\n","wandb_config['run_name'] = 'main_gy'\n","\n","### If you are using a CPU, please set wandb_config['use_gpu'] = 0 below. However, if you are using a GPU, leave it unchanged ####\n","wandb_config['use_gpu'] = 1\n","\n","# Number of times to pass through the data\n","wandb_config['num_epochs'] = 2\n","\n","wandb_config['git_dir'] = git_dir"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P-hgl7Wy4e5f"},"source":["### Create file list of all image files"]},{"cell_type":"code","metadata":{"id":"7wi3yLP74kLQ"},"source":["\n","len(('%s/data/CIFAR-10-images-master/train_gy/'%project_folder))\n","train_folder_files = os.listdir('%s/data/CIFAR-10-images-master/train_gy/'%project_folder)\n","random.shuffle(train_folder_files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YxzuDOUd6KnB"},"source":["total_points = len(train_folder_files)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v9SbXh_T6jLd"},"source":["#Setting 80% as training files and the last 20% as validation files\n","train_files = train_folder_files[:int(0.8*total_points)]\n","val_files = train_folder_files[int(0.8*total_points):]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fyTZuctJ6vSk"},"source":["test_files = os.listdir('%s/data/CIFAR-10-images-master/test/'%project_folder)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yo1qCG1X791Z"},"source":["Need to create txt files for train, val, and test; MAKE sure to indicate if train and val are rgb, gy, etc. "]},{"cell_type":"code","metadata":{"id":"IdCUNWGA7a5L"},"source":["#Using standard labeling we will create a dictionary for all the training files\n","#airplane = 0, automobile= 1; bird=2; cat=3; deer=4; \n","#dog=5; frog=6; horse=7; ship = 8; truck=9;\n","labels_dictionary = {}\n","with open('data/train_gy_file_list.txt','w') as F:\n","    for t in train_files:\n","        file_path = '%s/data/CIFAR-10-images-master/train_gy/%s'%(project_folder, t)\n","        if 'airplane' in t:\n","            labels_dictionary[file_path] = 0\n","            print(file_path, file = F)\n","        elif 'automobile' in t:\n","            labels_dictionary[file_path] = 1\n","            print(file_path, file = F)\n","        elif 'bird' in t:\n","            labels_dictionary[file_path] = 2\n","            print(file_path, file = F)\n","        elif 'cat' in t:\n","            labels_dictionary[file_path] = 3\n","            print(file_path, file = F)\n","        elif 'deer' in t:\n","            labels_dictionary[file_path] = 4\n","            print(file_path, file = F)\n","        elif 'dog' in t:\n","            labels_dictionary[file_path] = 5\n","            print(file_path, file = F)\n","        elif 'frog' in t:\n","            labels_dictionary[file_path] = 6\n","            print(file_path, file = F)  \n","        elif 'horse' in t:\n","            labels_dictionary[file_path] = 7\n","            print(file_path, file = F)\n","        elif 'ship' in t:\n","            labels_dictionary[file_path] = 8\n","            print(file_path, file = F)\n","        elif 'truck' in t:\n","            labels_dictionary[file_path] = 9\n","            print(file_path, file = F)\n","        \n","with open('data/val_gy_file_list.txt','w') as F:\n","    for t in train_files:\n","        file_path = '%s/data/CIFAR-10-images-master/train_gy/%s'%(project_folder, t)\n","        if 'airplane' in t:\n","            labels_dictionary[file_path] = 0\n","            print(file_path, file = F)\n","        elif 'automobile' in t:\n","            labels_dictionary[file_path] = 1\n","            print(file_path, file = F)\n","        elif 'bird' in t:\n","            labels_dictionary[file_path] = 2\n","            print(file_path, file = F)\n","        elif 'cat' in t:\n","            labels_dictionary[file_path] = 3\n","            print(file_path, file = F)\n","        elif 'deer' in t:\n","            labels_dictionary[file_path] = 4\n","            print(file_path, file = F)\n","        elif 'dog' in t:\n","            labels_dictionary[file_path] = 5\n","            print(file_path, file = F)\n","        elif 'frog' in t:\n","            labels_dictionary[file_path] = 6\n","            print(file_path, file = F)  \n","        elif 'horse' in t:\n","            labels_dictionary[file_path] = 7\n","            print(file_path, file = F)\n","        elif 'ship' in t:\n","            labels_dictionary[file_path] = 8\n","            print(file_path, file = F)\n","        elif 'truck' in t:\n","            labels_dictionary[file_path] = 9\n","            print(file_path, file = F)\n","\n","with open('data/test_file_list.txt','w') as F:\n","    for t in test_files:\n","        file_path = '%s/data/CIFAR-10-images-master/test/%s'%(project_folder, t)\n","        labels_dictionary[file_path] = -1\n","        print(file_path, file = F)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"-8BQ3T3C_-2X","executionInfo":{"status":"ok","timestamp":1618108391198,"user_tz":240,"elapsed":1054,"user":{"displayName":"Abraham Dada","photoUrl":"","userId":"04289475073988443676"}},"outputId":"5346d2ca-cc18-4659-9446-ef4b67555376"},"source":["random_data_point = random.choice(list(labels_dictionary.keys()))\n","plt.imshow(Image.open(random_data_point))\n","plt.title('Category: %s'%labels_dictionary[random_data_point])\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"mwqEND01AiZb"},"source":["with open('%s/data/labels_dictionary_gy.p'%project_folder, 'wb') as F:\n","    pickle.dump(labels_dictionary, F)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cn4zkTkjDLnD"},"source":["# Using custom data-loader"]},{"cell_type":"markdown","metadata":{"id":"C1AvUs13oCfg"},"source":["Since we formated the data the same, we will use the cat_dogs_loader"]},{"cell_type":"code","metadata":{"id":"RyoQmhKNmlB0"},"source":["file_list_loader= get_loader('cats_dogs_loader')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5yVfBGgEobQS"},"source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","     'test': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","    ]),\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gnMBD5M7dVi0"},"source":["dsets = {}\n","dsets['train'] = file_list_loader('/content/drive/MyDrive/Harvard_BAI/Colorblind_Machines_Neuro140/data/train_gy_file_list.txt','/content/drive/MyDrive/Harvard_BAI/Colorblind_Machines_Neuro140/data/labels_dictionary_gy.p', data_transforms['train'])\n","dsets['val'] = file_list_loader('/content/drive/MyDrive/Harvard_BAI/Colorblind_Machines_Neuro140/data/val_gy_file_list.txt','/content/drive/MyDrive/Harvard_BAI/Colorblind_Machines_Neuro140/data/labels_dictionary_gy.p', data_transforms['val'])\n","dsets['test'] = file_list_loader('/content/drive/MyDrive/Harvard_BAI/Colorblind_Machines_Neuro140/data/test_file_list.txt','/content/drive/MyDrive/Harvard_BAI/Colorblind_Machines_Neuro140/data/labels_dictionary_gy.p', data_transforms['test'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0MfcDHtqfUgH"},"source":["### Above, we created datasets. Now, we will pass them into pytorch's inbuild dataloaders, \n","### these will help us load batches of data for training.\n","dset_loaders = {}\n","dset_loaders['train'] = torch.utils.data.DataLoader(dsets['train'], batch_size=wandb_config['batch_size'], shuffle = True, num_workers=2,drop_last=False)\n","dset_loaders['val'] = torch.utils.data.DataLoader(dsets['val'], batch_size=wandb_config['batch_size'], shuffle = False, num_workers=2,drop_last=False)\n","dset_loaders['test'] = torch.utils.data.DataLoader(dsets['test'], batch_size=wandb_config['batch_size'], shuffle = True, num_workers=2,drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0FnZjmbfY7W"},"source":["data_sizes = {}\n","data_sizes['train'] = len(dsets['train'])\n","data_sizes['val'] = len(dsets['val'])\n","data_sizes['test'] = len(dsets['test'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oTChFSs7fcYH"},"source":["## Loading model with Pytorch"]},{"cell_type":"markdown","metadata":{"id":"EBqlEmUnfktj"},"source":["use resnet 18 bc easier to train"]},{"cell_type":"code","metadata":{"id":"Ydp6YEqZfik1"},"source":["model = torchvision.models.resnet18(pretrained = False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QKmNN8JnfxPB"},"source":["### use get model to load CNN"]},{"cell_type":"code","metadata":{"id":"ofvHKm47MxST"},"source":["### Since we pass ResNet18 below, this will get relayed to \n","### the get_model function loaded from models.py. \n","### As you can see, that would load the resnet18 model from the file\n","### ResNet18.py at `res/models/`.\n","model = get_model('ResNet18', 1000)\n","in_filters = model.fc.in_features\n","model.fc = nn.Linear(in_features=in_filters, out_features=wandb_config['num_classes'])\n","model.cuda();\n","\n","\n","## 10 classes"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RQlm_rABgYmB"},"source":["### MAIN_PRO Anatomy"]},{"cell_type":"markdown","metadata":{"id":"psfnsuSmgfUC"},"source":["#### Below we have the function which trains, tests and returns the best model weights."]},{"cell_type":"code","metadata":{"id":"0ZFAFtycgcQ0"},"source":["def model_pipeline(model, criterion, optimizer, dset_loaders, dset_sizes, hyperparameters):\n","    with wandb.init(project=\"HARVARD_BAI\", config=hyperparameters):\n","        if hyperparameters['run_name']:\n","            wandb.run.name = hyperparameters['run_name']\n","        config = wandb.config\n","        best_model = model\n","        best_acc = 0.0\n","        \n","        print(config)\n","        \n","        print(config.num_epochs)\n","        for epoch_num in range(config.num_epochs):\n","            wandb.log({\"Current Epoch\": epoch_num})\n","            model = train_model(model, criterion, optimizer, dset_loaders, dset_sizes, config)\n","            best_acc, best_model = val_model(model, best_acc, best_model, dset_loaders, dset_sizes, config)\n","    \n","    return best_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A2rsNO8ugoqD"},"source":["#### Different Steps of train model function"]},{"cell_type":"code","metadata":{"id":"HnRnYlg2gufC"},"source":["def train_model(model, criterion, optimizer, dset_loaders, dset_sizes, configs):\n","    print('Starting training epoch...')\n","    best_model = model\n","    best_acc = 0.0\n","\n","    \n","    ### This tells python to track gradients. While testing weights aren't updated hence they are not stored.\n","    model.train() \n","    running_loss = 0.0\n","    running_corrects = 0\n","    iters = 0\n","    \n","    \n","    ### We loop over the data loader we created above. Simply using a for loop.\n","    for data in tqdm(dset_loaders['train']):\n","        inputs, labels = data\n","        \n","        ### If you are using a gpu, then script will move the loaded data to the GPU. \n","        ### If you are not using a gpu, ensure that wandb_configs['use_gpu'] is set to False above.\n","        if configs.use_gpu:\n","            inputs = inputs.float().cuda()\n","            labels = labels.long().cuda()\n","        else:\n","            print('WARNING: NOT USING GPU!')\n","            inputs = inputs.float()\n","            labels = labels.long()\n","\n","        \n","        ### We set the gradients to zero, then calculate the outputs, and the loss function. \n","        ### Gradients for this process are automatically calculated by PyTorch.\n","        \n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs.data, 1)\n","\n","        loss = criterion(outputs, labels)\n","        \n","        \n","        ### At this point, the program has calculated gradient of loss w.r.t. weights of our NN model.\n","        loss.backward()\n","        optimizer.step()\n","        \n","        ### optimizer.step() updated the models weights using calculated gradients.\n","        \n","        ### Let's store these and log them using wandb. They will be displayed in a nice online\n","        ### dashboard for you to see.\n","        \n","        iters += 1\n","        running_loss += loss.item()\n","        running_corrects += torch.sum(preds == labels.data)\n","        wandb.log({\"train_running_loss\": running_loss/float(iters*len(labels.data))})\n","        wandb.log({\"train_running_corrects\": running_corrects/float(iters*len(labels.data))})\n","\n","    epoch_loss = float(running_loss) / dset_sizes['train']\n","    epoch_acc = float(running_corrects) / float(dset_sizes['train'])\n","    wandb.log({\"train_accuracy\": epoch_acc})\n","    wandb.log({\"train_loss\": epoch_loss})\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7_4latKMg01p"},"source":["def val_model(model, best_acc, best_model, dset_loaders, dset_sizes, configs):\n","    print('Starting testing epoch...')\n","    model.eval() ### tells pytorch to not store gradients as we won't be updating weights while testing.\n","\n","    running_corrects = 0\n","    iters = 0   \n","    for data in tqdm(dset_loaders['val']):\n","        inputs, labels = data\n","        if configs.use_gpu:\n","            inputs = inputs.float().cuda()\n","            labels = labels.long().cuda()\n","        else:\n","            print('WARNING: NOT USING GPU!')\n","            inputs = inputs.float()\n","            labels = labels.long()\n","\n","        \n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs.data, 1)\n","        \n","        iters += 1\n","        running_corrects += torch.sum(preds == labels.data)\n","        wandb.log({\"train_running_corrects\": running_corrects/float(iters*len(labels.data))})\n","\n","\n","    epoch_acc = float(running_corrects) / float(dset_sizes['val'])\n","\n","    wandb.log({\"test_accuracy\": epoch_acc})\n","    \n","    ### Code is very similar to train set. One major difference, we don't update weights. \n","    ### We only check the performance is best so far, if so, we save this model as the best model so far.\n","    \n","    if epoch_acc > best_acc:\n","        best_acc = epoch_acc\n","        best_model = copy.deepcopy(model)\n","    wandb.log({\"best_accuracy\": best_acc})\n","    \n","    return best_acc, best_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"28YguvfIg6pP"},"source":["# Use wandb"]},{"cell_type":"code","metadata":{"id":"mG7k_6aVg-WE"},"source":["### Criterion is simply specifying what loss to use. Here we choose cross entropy loss. \n","criterion = nn.CrossEntropyLoss()\n","\n","### tells what optimizer to use. There are many options, we here choose Adam.\n","### the main difference between optimizers is that they vary in how weights are updated based on calculated gradients.\n","optimizer_ft = optim.Adam(model.parameters(), lr = wandb_config['base_lr'])\n","\n","if wandb_config['use_gpu']:\n","    criterion.cuda()\n","    model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qd3wFwd4hAuI"},"source":["### Creating the folder where our models will be saved.\n","if not os.path.isdir(\"%s/saved_models_rgb/\"%wandb_config['git_dir']):\n","    os.mkdir(\"%s/saved_models_rgb/\"%wandb_config['git_dir'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHZbo6t0hXWg"},"source":["os.environ[\"WANDB_START_METHOD\"] = \"fork\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zzU_ewEhJaT","colab":{"base_uri":"https://localhost:8080/","height":392},"executionInfo":{"status":"error","timestamp":1618108508027,"user_tz":240,"elapsed":41887,"user":{"displayName":"Abraham Dada","photoUrl":"","userId":"04289475073988443676"}},"outputId":"139c40e8-86d4-4f8b-b46f-bae89b6b0307"},"source":["### Let's run it all, and save the final best model.\n","best_final_model = model_pipeline(model, criterion, optimizer_ft, dset_loaders, data_sizes, wandb_config)\n","\n","\n","save_path = '%s/saved_models/%s_final.pt'%(wandb_config['git_dir'], wandb_config['run_name'])\n","with open(save_path,'wb') as F:\n","    torch.save(best_final_model,F)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Problem at: <ipython-input-25-8bf84bf4393a> 2 model_pipeline\n"],"name":"stdout"},{"output_type":"error","ename":"UsageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUsageError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-6b6ec318ec86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Let's run it all, and save the final best model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_final_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s/saved_models/%s_final.pt'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwandb_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'git_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwandb_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-8bf84bf4393a>\u001b[0m in \u001b[0;36mmodel_pipeline\u001b[0;34m(model, criterion, optimizer, dset_loaders, dset_sizes, hyperparameters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdset_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HARVARD_BAI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'run_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m                 \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run resumed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUsageError\u001b[0m: Error communicating with wandb process, try setting WANDB_START_METHOD=fork"]}]},{"cell_type":"markdown","metadata":{"id":"XDfiHYhDiIei"},"source":["# Wandb workaround"]},{"cell_type":"code","metadata":{"id":"vzkEcSZwiLZ2"},"source":["from IPython.display import clear_output "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":713,"referenced_widgets":["0881cb5af516407686f5095fd5f3ef41","1db1921b86f9416e84a2fbd81f2cd9b8","44c8048dec0044d48f41f600bee5ab91","4e3f12d708534e43b854dbaccad849d9","13a61e6f59234d46b1323ac6543e0f80","84baaa2c82c54781a56f664bf44aa412","30689d20f5f244f5a551cb877384d506","4ce65d6acc984aab91ff687bf96f1c48"]},"id":"6mQaatp-iN2L","executionInfo":{"status":"error","timestamp":1618108520078,"user_tz":240,"elapsed":1440,"user":{"displayName":"Abraham Dada","photoUrl":"","userId":"04289475073988443676"}},"outputId":"5f196792-dd98-4c4a-f248-2d2f71f67d7e"},"source":["df_gy=[]\n","losses = []\n","for epoch in range(2):\n","    for data in tqdm(dset_loaders['train']):\n","        inputs, labels, _ = data\n","        \n","        ### If you are using a gpu, then script will move the loaded data to the GPU. \n","        ### If you are not using a gpu, ensure that wandb_configs['use_gpu'] is set to False above.\n","        if wandb_config['use_gpu']:\n","            inputs = inputs.float().cuda()\n","            labels = labels.long().cuda()\n","        else:\n","            print('WARNING: NOT USING GPU!')\n","            inputs = inputs.float()\n","            labels = labels.long()\n","\n","        \n","        ### We set the gradients to zero, then calculate the outputs, and the loss function. \n","        ### Gradients for this process are automatically calculated by PyTorch.\n","        \n","        optimizer_ft.zero_grad()\n","        outputs = model(inputs)\n","        _, preds = torch.max(outputs.data, 1)\n","\n","        loss = criterion(outputs, labels)\n","     \n","        \n","        ### At this point, the program has calculated gradient of loss w.r.t. weights of our NN model.\n","        loss.backward()\n","        optimizer_ft.step()\n","        losses.append(loss)\n","        df_gy.append({\"model\": \"ResNet-18 GY\", \"epoch\": epoch, \"loss\": loss})\n","        clear_output()\n","        plt.plot(losses)\n","        plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0881cb5af516407686f5095fd5f3ef41","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4001.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-876949778ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdset_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/drive/MyDrive/Harvard_BAI/res/loader/cats_dogs_loader.py\", line 60, in __getitem__\n    transformed_sample = self.transform(sample)\n  File \"/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\", line 60, in __call__\n    img = t(img)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n    result = self.forward(*input, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py\", line 221, in forward\n    return F.normalize(tensor, self.mean, self.std, self.inplace)\n  File \"/usr/local/lib/python3.7/dist-packages/torchvision/transforms/functional.py\", line 336, in normalize\n    tensor.sub_(mean).div_(std)\nRuntimeError: output with shape [1, 224, 224] doesn't match the broadcast shape [3, 224, 224]\n"]}]},{"cell_type":"code","metadata":{"id":"k3LQJZQQorxI"},"source":["# Keep save output in csv\n","import csv\n","with open(\"df_gy.csv\", \"w\", newline=\"\") as csv_file:\n","  cols=[\"model\", \"epoch\", \"loss\"]\n","  writer= csv.DictWriter(csv_file, fieldnames=cols)\n","  writer.writeheader()\n","  writer.writerows(df_gy)"],"execution_count":null,"outputs":[]}]}